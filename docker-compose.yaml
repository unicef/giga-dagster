x-dagster-common-config: &dagster-common-config
  init: true
  restart: unless-stopped
  env_file: ./dagster/.env

x-spark-common-config: &spark-common-config
  user: "1001:1001"
  image: bitnami/spark:3.5.0
  restart: unless-stopped
  init: true
  env_file: ./spark/.env

x-spark-common-env: &spark-common-env
  SPARK_RPC_AUTHENTICATION_ENABLED: "yes"
  SPARK_RPC_ENCRYPTION: "yes"

services:
  dagster-storage:
    <<: *dagster-common-config
    image: bitnami/postgresql:14
    volumes:
      - dagster-storage:/bitnami/postgresql

  dagster-webserver:
    <<: *dagster-common-config
    build: ./dagster
    image: unicef/giga-dataops-platform/dagster
    environment:
      DAGSTER_HOME: /app
    volumes:
      - ./dagster:/app
    depends_on:
      - dagster-storage
    ports:
      - "3001:3002"

  dagster-webserver-readonly:
    <<: *dagster-common-config
    command:
      - "dagster-webserver"
      - "-h"
      - "0.0.0.0"
      - "-p"
      - "3003"
      - "--read-only"
    build: ./dagster
    image: unicef/giga-dataops-platform/dagster
    environment:
      DAGSTER_HOME: /app
    volumes:
      - ./dagster:/app
    depends_on:
      - dagster-storage
    ports:
      - "3003:3003"

    #  spark-master:
    #    <<: *spark-common-config
    #    environment:
    #      <<: *spark-common-env
    #      SPARK_MODE: master
    #      SPARK_MASTER_PORT: 7077
    #      SPARK_MASTER_WEBUI_PORT: 8070
    #    ports:
    #      - "7077:7077"
    #      - "8070:8070"

  spark-master:
    <<: *spark-common-config
    environment:
      <<: *spark-common-env
      SPARK_MODE: master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8070
    command:
      - sbin/start-connect-server.sh
      - --packages
      - org.apache.spark:spark-connect_2.12:3.5.0,io.delta:delta-spark_2.12:3.0.0
      - --conf
      - fs.azure.account.auth.type.${AZURE_STORAGE_ACCOUNT_NAME}.dfs.core.windows.net=SharedKey
      - --conf
      - fs.azure.account.key.${AZURE_STORAGE_ACCOUNT_NAME}.dfs.core.windows.net=${AZURE_SAS_TOKEN}
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    tmpfs:
      - /tmp/spark-events:mode=770,size=100m,uid=1001,gid=1001
    ports:
      - "8070:8070"
      - "15002:15002"

#  spark-worker:
#    <<: *spark-common-config
#    environment:
#      <<: *spark-common-env
#      SPARK_MODE: worker
#      SPARK_MASTER_URL: spark://spark-master:7077
#      SPARK_WORKER_CORES: 1
#      SPARK_WORKER_MEMORY: 256M
#    deploy:
#      mode: replicated
#      replicas: 3
#      endpoint_mode: dnsrr
#      restart_policy:
#        condition: on-failure
#        delay: 5s
#        max_attempts: 3
#        window: 120s

#  authproxy:
#    <<: *common-config
#    build: ./authproxy
#    image: unicef/giga-dataops-platform/dagster-authproxy
#    env_file: ./authproxy/.env
#    volumes:
#      - ./authproxy:/app
#    ports:
#      - "3001:3001"

volumes:
  dagster-storage:
  metastore-data:
